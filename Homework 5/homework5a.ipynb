{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "%matplotlib inline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1: K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tree_dbh</th>\n",
       "      <th>spc_latin</th>\n",
       "      <th>root_stone</th>\n",
       "      <th>root_grate</th>\n",
       "      <th>root_other</th>\n",
       "      <th>trunk_wire</th>\n",
       "      <th>trnk_light</th>\n",
       "      <th>trnk_other</th>\n",
       "      <th>brch_light</th>\n",
       "      <th>brch_shoe</th>\n",
       "      <th>brch_other</th>\n",
       "      <th>health</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21</td>\n",
       "      <td>Quercus palustris</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Fair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Gleditsia triacanthos var. inermis</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>Gleditsia triacanthos var. inermis</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>Gleditsia triacanthos var. inermis</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>Gleditsia triacanthos var. inermis</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tree_dbh                           spc_latin root_stone root_grate  \\\n",
       "0        21                   Quercus palustris        Yes         No   \n",
       "1         3  Gleditsia triacanthos var. inermis         No         No   \n",
       "2        10  Gleditsia triacanthos var. inermis        Yes         No   \n",
       "3        11  Gleditsia triacanthos var. inermis         No         No   \n",
       "4        11  Gleditsia triacanthos var. inermis         No         No   \n",
       "\n",
       "  root_other trunk_wire trnk_light trnk_other brch_light brch_shoe brch_other  \\\n",
       "0         No         No         No         No         No        No         No   \n",
       "1         No         No         No         No         No        No         No   \n",
       "2         No         No         No         No         No        No         No   \n",
       "3         No         No         No         No         No        No         No   \n",
       "4         No         No         No         No         No        No         No   \n",
       "\n",
       "  health  \n",
       "0   Fair  \n",
       "1   Good  \n",
       "2   Good  \n",
       "3   Good  \n",
       "4   Good  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read data\n",
    "trees = pd.read_csv('HW5a_nyc_trees.csv', sep=',', names = ['tree_dbh','spc_latin','root_stone','root_grate','root_other','trunk_wire','trnk_light','trnk_other','brch_light','brch_shoe',\n",
    "                                                            'brch_other','health'], header = None, skiprows = 1)\n",
    "trees.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tree_dbh</th>\n",
       "      <th>root_stone</th>\n",
       "      <th>root_grate</th>\n",
       "      <th>root_other</th>\n",
       "      <th>trunk_wire</th>\n",
       "      <th>trnk_light</th>\n",
       "      <th>trnk_other</th>\n",
       "      <th>brch_light</th>\n",
       "      <th>brch_shoe</th>\n",
       "      <th>brch_other</th>\n",
       "      <th>spc_latin_Gleditsia triacanthos var. inermis</th>\n",
       "      <th>spc_latin_Platanus x acerifolia</th>\n",
       "      <th>spc_latin_Pyrus calleryana</th>\n",
       "      <th>spc_latin_Quercus palustris</th>\n",
       "      <th>health_Fair</th>\n",
       "      <th>health_Good</th>\n",
       "      <th>health_Poor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tree_dbh  root_stone  root_grate  root_other  trunk_wire  trnk_light  \\\n",
       "0        21           1           0           0           0           0   \n",
       "1         3           0           0           0           0           0   \n",
       "2        10           1           0           0           0           0   \n",
       "3        11           0           0           0           0           0   \n",
       "4        11           0           0           0           0           0   \n",
       "\n",
       "   trnk_other  brch_light  brch_shoe  brch_other  \\\n",
       "0           0           0          0           0   \n",
       "1           0           0          0           0   \n",
       "2           0           0          0           0   \n",
       "3           0           0          0           0   \n",
       "4           0           0          0           0   \n",
       "\n",
       "   spc_latin_Gleditsia triacanthos var. inermis  \\\n",
       "0                                             0   \n",
       "1                                             1   \n",
       "2                                             1   \n",
       "3                                             1   \n",
       "4                                             1   \n",
       "\n",
       "   spc_latin_Platanus x acerifolia  spc_latin_Pyrus calleryana  \\\n",
       "0                                0                           0   \n",
       "1                                0                           0   \n",
       "2                                0                           0   \n",
       "3                                0                           0   \n",
       "4                                0                           0   \n",
       "\n",
       "   spc_latin_Quercus palustris  health_Fair  health_Good  health_Poor  \n",
       "0                            1            1            0            0  \n",
       "1                            0            0            1            0  \n",
       "2                            0            0            1            0  \n",
       "3                            0            0            1            0  \n",
       "4                            0            0            1            0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############# PART A ##################\n",
    "# transform other columns so binary values are transformed to 0 and 1\n",
    "binary_cols = np.array(['root_stone','root_grate','root_other','trunk_wire','trnk_light','trnk_other','brch_light','brch_shoe','brch_other'])\n",
    "for i in binary_cols:\n",
    "    trees[i] = trees[i].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "# transform latin name and health so categorical values are one-hot encoded\n",
    "trees = pd.get_dummies(trees, columns = ['spc_latin','health'])\n",
    "trees.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for k = 10 with 25000 training points is 84.485%\n"
     ]
    }
   ],
   "source": [
    "############# PART B ##################\n",
    "validation_data_length = 25000\n",
    "\n",
    "# split data into training and validation sets\n",
    "trees_training = trees.iloc[:-validation_data_length,:]\n",
    "trees_validation = trees.iloc[-validation_data_length:,:]\n",
    "\n",
    "# implement k nearest neighbors algorithm using euclidean distance as the distance metric\n",
    "def knn(k, training_data, validation_data, health_values_int):\n",
    "\n",
    "    # initialize empty array to store predicted values\n",
    "    predicted_values = np.zeros([validation_data.shape[0],health_values_int])\n",
    "    # loop through each row in the validation data\n",
    "    for i in range(validation_data.shape[0]):\n",
    "        # calculate euclidean distance between each row in the training data and the current row in the validation data\n",
    "        diff = training_data.iloc[:,:-health_values_int].values - validation_data.iloc[i,:-health_values_int].values\n",
    "        euclidean_distance = np.sqrt(np.sum(np.square(diff), axis=1))\n",
    "\n",
    "        # sort the euclidean distance array and get the indices of the k smallest values\n",
    "        k_smallest_indices = np.argpartition(euclidean_distance, k)[:k]\n",
    "\n",
    "        # get the health values of the k nearest neighbors\n",
    "        k_smallest_health_values = training_data.iloc[k_smallest_indices,-health_values_int:].values\n",
    "\n",
    "        # get the mode of the k_smallest_health_values array\n",
    "        test = np.sum(k_smallest_health_values, axis = 0)\n",
    "        # get index of the maximum value in the test array\n",
    "        predicted_values[i] = np.zeros(health_values_int, dtype = int)\n",
    "        predicted_values[i][np.argmax(test)] = 1\n",
    "\n",
    "    return predicted_values\n",
    "\n",
    "# test the k nearest neighbors algorithm for different values of k\n",
    "# k = [1, 10, 100]\n",
    "k = [10]\n",
    "health_values_int = 3\n",
    "for i in k:\n",
    "    for j in range(25000,25001,25000):\n",
    "        predicted_values = knn(i, trees_training.iloc[:j,:], trees_validation, health_values_int)\n",
    "        print('Accuracy for k = ' + str(i) + ' with ' + str(j) + ' training points is ' + str(np.round(100*np.sum(predicted_values == trees_validation.iloc[:,-3:].values)/(health_values_int*trees_validation.shape[0]),3)) + '%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix for k = 10 with 25000 training points is:\n",
      "[[    6.    12.     6.]\n",
      " [  143.   352.   671.]\n",
      " [  757.  4229. 18824.]]\n"
     ]
    }
   ],
   "source": [
    "# Provide \"confusion matrix\" for the best k and n\n",
    "k = 10\n",
    "# n = 200000\n",
    "n = 25000\n",
    "# predicted_values = knn(k, trees_training.iloc[:n,:], trees_validation, health_values_int)\n",
    "print('Confusion matrix for k = ' + str(k) + ' with ' + str(n) + ' training points is:')\n",
    "\n",
    "confusion = np.zeros([health_values_int,health_values_int])\n",
    "k = 0\n",
    "l = 0\n",
    "for i in [2,0,1]:\n",
    "    for j in [2,0,1]:\n",
    "        confusion[k,l] = np.sum((predicted_values[:,i] == 1) & (trees_validation.iloc[:,-health_values_int:].values[:,j] == 1))\n",
    "        l += 1\n",
    "    l = 0\n",
    "    k += 1\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "print(confusion)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part B Comments\n",
    "With a 25000 length validation dataset, my algorithm takes almost 2 minutes to run against just 25000 training points (I comment on possible ways to improve the speed of the algorithm after part C). Therefore, I tested the algorithm with only 2000 validation points against different sizes of training data and different values of k. I determined that k = 10 was one of the better k values, so I ran the algorithm with k = 10 for all 25000 validation points. Part of the reason the algorithm has a fairly high accuracy of ~85% is just because most of the trees have 'good' health, as is shown by the results of the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for k = 1 with 25000 training points is 66.012%\n",
      "Accuracy for k = 1 with 50000 training points is 68.664%\n",
      "Accuracy for k = 1 with 75000 training points is 66.784%\n",
      "Accuracy for k = 1 with 100000 training points is 67.156%\n",
      "Accuracy for k = 1 with 125000 training points is 65.788%\n",
      "Accuracy for k = 1 with 150000 training points is 68.848%\n",
      "Accuracy for k = 1 with 175000 training points is 67.524%\n",
      "Accuracy for k = 10 with 25000 training points is 73.232%\n",
      "Accuracy for k = 10 with 50000 training points is 73.98%\n",
      "Accuracy for k = 10 with 75000 training points is 73.216%\n",
      "Accuracy for k = 10 with 100000 training points is 73.196%\n",
      "Accuracy for k = 10 with 125000 training points is 73.8%\n",
      "Accuracy for k = 10 with 150000 training points is 73.756%\n",
      "Accuracy for k = 10 with 175000 training points is 72.136%\n",
      "Accuracy for k = 100 with 25000 training points is 77.78%\n",
      "Accuracy for k = 100 with 50000 training points is 77.944%\n",
      "Accuracy for k = 100 with 75000 training points is 77.932%\n",
      "Accuracy for k = 100 with 100000 training points is 77.932%\n",
      "Accuracy for k = 100 with 125000 training points is 77.896%\n",
      "Accuracy for k = 100 with 150000 training points is 77.932%\n",
      "Accuracy for k = 100 with 175000 training points is 77.908%\n"
     ]
    }
   ],
   "source": [
    "############# PART C ##################\n",
    "# import warnings filter\n",
    "from warnings import simplefilter\n",
    "# ignore all future warnings\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "# implement k nearest neighbors algorithm using sklearn.neighbors.KNeighborsClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "k = [1, 10, 100]\n",
    "for i in k:\n",
    "    for j in range(25000,200000,25000):\n",
    "        knn = KNeighborsClassifier(n_neighbors = i)\n",
    "        knn.fit(trees_training.iloc[:j,:-3], trees_training.iloc[:j,-3:])\n",
    "        print('Accuracy for k = ' + str(i) + ' with ' + str(j) + ' training points is ' + str(np.round(100*knn.score(trees_validation.iloc[:,:-3], trees_validation.iloc[:,-3:]),3)) + '%')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part C Comments\n",
    "Clearly, the scikit-learn implementation of the KNN algorithm is WAY faster than my algorithm. This algorithm was able to run 20 times with more training points than my algorithm in the same amount of time it took my algorithm to run just once. There's a few things I could do to improve the speed of my algorithm:\n",
    "1. Use 'csr_matrix' from scikit-learn to turn the training data into a sparse representation because most of the features are 0\n",
    "2. Use an algorithm like 'Ball Tree' or 'K-D Tree' to find the nearest neighbors much faster. The scikit implementation of KNN uses one of these algorithms which decreases the accuracy of the results slightly but speeds up the search by more than an order of magnitude."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2: Spam Text Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  category                                            message\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "# read data\n",
    "messages = pd.read_csv('HW5a_ham_spam.csv', sep=',', names = ['category','message'], header = None, skiprows = 1)\n",
    "messages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexh\\AppData\\Local\\Temp\\ipykernel_6096\\3502801304.py:4: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  messages['message'] = messages['message'].str.replace('[^a-zA-Z0-9]', ' ')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>go until jurong point crazy available only in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>u dun say so early hor u c already then say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>nah i don t think he go to usf he life around ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  category                                            message\n",
       "0      ham  go until jurong point crazy available only in ...\n",
       "1      ham                            ok lar joking wif u oni\n",
       "2     spam  free entry in 2 a wkly comp to win fa cup fina...\n",
       "3      ham        u dun say so early hor u c already then say\n",
       "4      ham  nah i don t think he go to usf he life around ..."
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############# PART A ##################\n",
    "\n",
    "# remove all non-alphanumeric characters from messages\n",
    "messages['message'] = messages['message'].str.replace('[^a-zA-Z0-9]', ' ')\n",
    "\n",
    "# convert all messages to lowercase\n",
    "messages['message'] = messages['message'].str.lower()\n",
    "\n",
    "# word tokenize messages for lemmatizer\n",
    "messages['message'] = messages['message'].apply(nltk.word_tokenize)\n",
    "\n",
    "# lemmatize messages\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "messages['message'] = messages['message'].apply(lambda x: ' '.join([lemmatizer.lemmatize(word) for word in x]))\n",
    "\n",
    "# word tokenize messages again\n",
    "# messages['message'] = messages['message'].apply(nltk.word_tokenize)\n",
    "\n",
    "messages.head()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part A Comments\n",
    "Tokenization separates each sentence into individual words, and lemmatization reduces words, usually verbs, to their base form. Tokenization allows us to analyze the data easier by picking out individual words rather than looking at whole complicated sentences. Lemmatization reduces noise in the data by combining words that essentially have the same meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# PART B ##################\n",
    "\n",
    "# generate multinomial features based on the number of occurrences of a set of words in the message using CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# split messages into training and validation sets\n",
    "validation_data_length = 500\n",
    "messages_training = messages.iloc[:-validation_data_length,:]\n",
    "messages_validation = messages.iloc[-validation_data_length:,:]\n",
    "\n",
    "# look at only most frequenct m words\n",
    "m = [5, 10, 100, 500, 1000, 2500]\n",
    "\n",
    "# initalize empty lists to hold feature names and count features\n",
    "feature_names = []\n",
    "count_features = []\n",
    "\n",
    "# apply CountVectorizer to messages\n",
    "for i in m:\n",
    "    count_vectorizer = CountVectorizer(stop_words='english', max_features=i)\n",
    "    count_features_temp = count_vectorizer.fit_transform(messages_training['message'])\n",
    "    count_features_temp = count_features_temp.toarray()\n",
    "    count_features.append(count_features_temp)\n",
    "    feature_names.append(count_vectorizer.get_feature_names())\n",
    "\n",
    "# now we have a list of count features and feature names for each value of m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# PART C ##################\n",
    "\n",
    "# implement soft-margin SVM with c = 0.1 to classify the 6 datasets\n",
    "c = 0.1\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
